from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

# 圖片設定
IMG_SIZE = (64, 64)
BATCH_SIZE = 32

# 解壓後的 hurricane 資料夾
DATA_DIR = "hurricane"  # 確保這個資料夾結構是 hurricane/damaged 和 hurricane/no_damaged

# 預處理資料
datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_gen = datagen.flow_from_directory(
    DATA_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
    subset="training"
)

val_gen = datagen.flow_from_directory(
    DATA_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
    subset="validation"
)




from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Dropout, Input, Rescaling

fnn_model = Sequential([
    Input(shape=(64, 64, 3)),
    Flatten(),
    Rescaling(1./255),
    Dense(128, activation="relu"),
    Dropout(0.3),
    Dense(64, activation="relu"),
    Dropout(0.3),
    Dense(1, activation="sigmoid")
])

fnn_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
fnn_history = fnn_model.fit(train_gen, validation_data=val_gen, epochs=10)



from tensorflow.keras.layers import Conv2D, MaxPooling2D

cnn_model = Sequential([
    Input(shape=(64,64,3)),
    Rescaling(1./255),
    Conv2D(32,3,activation="relu", padding="same"),
    MaxPooling2D()
    Conv2D(Conv2D(64,3,activation="relu", padding="same"),
    MaxPooling2D(),
           
    Flatten()
                
                
                
                )
